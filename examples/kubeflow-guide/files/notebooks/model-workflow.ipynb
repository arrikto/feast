{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fetch Features for Training Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from feast import Entity, FeatureStore, FeatureView, Field\n",
    "from feast.infra.offline_stores.contrib.postgres_offline_store.postgres_source import (\n",
    "    PostgreSQLSource,\n",
    ")\n",
    "from feast.infra.offline_stores.contrib.postgres_offline_store.postgres import PostgreSQLOfflineStoreConfig\n",
    "from feast.infra.online_stores.redis import RedisOnlineStoreConfig\n",
    "from feast.repo_config import RepoConfig, RegistryConfig\n",
    "from feast.types import Float32, Int64\n",
    "\n",
    "from kale.common import mlmdutils, artifacts\n",
    "from kale.ml import Signature\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def get_sqlalchemy_engine(config):\n",
    "    url = f\"postgresql+psycopg2://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "    print(\"Connecting to\", config[\"db_schema\"], \"schema using:\", url)\n",
    "    return sqlalchemy.create_engine(url, client_encoding='utf8', connect_args={'options': '-c search_path={}'.format(config[\"db_schema\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_config = {\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"host\": \"postgresql-offline-store.default.svc.cluster.local\",\n",
    "        \"port\": 5432,\n",
    "        \"database\": \"postgres\",\n",
    "        \"db_schema\": \"public\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "END_DATE = datetime.utcnow()\n",
    "START_DATE = END_DATE - timedelta(days=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Building & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the purpose of this guide, we decided to use supervised learning to create a model that predicts whether a driver will complete an order.\n",
    "\n",
    "This model takes as input the:\n",
    "- daily acceptance rate = accepted trip orders / total trip orders (per day)\n",
    "- daily completion rate = completed trips / accepted trip orders (per day)\n",
    "- daily trips = count of completed trips in a day\n",
    "- daily profit = sum of completed trips in a day\n",
    "\n",
    "and the output we get is a boolean flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We start by fetching the `trip_records` dataset.\n",
    "\n",
    "This is our entity dataframe (our entity is the driver), thus we only need to fetch the `driver_id`, `event_timestamp` and `completed` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:build_model"
    ]
   },
   "outputs": [],
   "source": [
    "con = get_sqlalchemy_engine(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"\"\"SELECT driver_id, event_timestamp, completed \\\n",
    "FROM trip_records \\\n",
    "WHERE event_timestamp BETWEEN '{START_DATE}' AND '{END_DATE}'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver_orders = pd.read_sql(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver_orders[\"completed\"] = driver_orders.apply(lambda x: 1 if x[\"completed\"] == True else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver_orders.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enrich Dataset using Feast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We enrich the dataset using the `get_historical_features()` method.\n",
    "\n",
    "This method joins historical feature data from one or more feature views to an entity dataframe by using a time travel join. It is generally used either for training or for batch scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offline_store_config = PostgreSQLOfflineStoreConfig(\n",
    "    host=\"postgresql-offline-store.default.svc.cluster.local\",\n",
    "    database=\"postgres\",\n",
    "    db_schema=\"public\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "online_store_config = RedisOnlineStoreConfig(\n",
    "    connection_string=\"redis-online-store.default.svc.cluster.local:6379,username=default,password=redis,db=0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry_config = RegistryConfig(\n",
    "    registry_store_type=\"KubeflowRegistryStore\",\n",
    "    path=\"\",\n",
    "    project=\"kubeflow-user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_config = RepoConfig(\n",
    "    project=\"kubeflow-user\",\n",
    "    registry=registry_config,\n",
    "    provider=\"local\",\n",
    "    offline_store=offline_store_config,\n",
    "    online_store=online_store_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(config=repo_config, repo_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver_stats = fs.get_historical_features(\n",
    "    entity_df=driver_orders,\n",
    "    features=[\n",
    "        \"daily_driver_stats_fv:comp_rate\",\n",
    "        \"daily_driver_stats_fv:acc_rate\",\n",
    "        \"daily_driver_stats_fv:trips\",\n",
    "        \"daily_driver_stats_fv:profit\",\n",
    "    ],\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Building a model is usually a complex and experimental phase of the process. In this guide we decide to use a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are now ready to split our dataset and train the model using the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:train_model",
     "prev:build_model"
    ]
   },
   "outputs": [],
   "source": [
    "x = driver_stats[[\n",
    "    \"comp_rate\",\n",
    "    \"acc_rate\",\n",
    "    \"trips\",\n",
    "    \"profit\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = driver_stats[[\"completed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next step, is to evaluate the model and once its performance is satisfactory we are ready to deploy it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:evaluate_model",
     "prev:train_model"
    ]
   },
   "outputs": [],
   "source": [
    "performance = model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Model performance:\", performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "To deploy a model we will package it and store it as artifact in MLMD first.\n",
    "\n",
    "When trying to make a prediction we just want to provide a driver id and get back whether this driver will complete the ride (True or False).\n",
    "\n",
    "We will use the online store to get the latest features for each driver that will use as input for the model.\n",
    "\n",
    "Thus, we need to create a Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The Transformer during the `__init__()` method configures the feature store.\n",
    "\n",
    "Every time it receives an input (driver_id) uses the `get_online_features()` to fetch the latest feature data (comp_rate, acc_rate, trips, profit) of the driver.\n",
    "\n",
    "Then, the Transformer channels the feature data to the model that returns the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:package_model",
     "prev:evaluate_model"
    ]
   },
   "outputs": [],
   "source": [
    "ASSETS_PATH = \"/home/jovyan/transformer_package/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.mkdir(ASSETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRANSFORMER_CODE = \"\"\"\n",
    "import kfserving\n",
    "from typing import Dict\n",
    "\n",
    "from feast import FeatureStore\n",
    "from feast.infra.online_stores.redis import RedisOnlineStoreConfig\n",
    "from feast.repo_config import RepoConfig, RegistryConfig\n",
    "\n",
    "class Transformer(kfserving.KFModel):\n",
    "    def __init__(self, model_name: str, predictor_host: str, protocol: str = \"v1\"):\n",
    "        super().__init__(model_name)\n",
    "        self.predictor_host = predictor_host\n",
    "        self.protocol = protocol\n",
    "        \n",
    "        online_store_config = RedisOnlineStoreConfig(\n",
    "            connection_string=\"redis-online-store.default.svc.cluster.local:6379,username=default,password=redis,db=0\"\n",
    "        )\n",
    "        \n",
    "        registry_config = RegistryConfig(\n",
    "            registry_store_type=\"KubeflowRegistryStore\",\n",
    "            path=\"\",\n",
    "            project=\"kubeflow-user\"\n",
    "        )\n",
    "        \n",
    "        repo_config = RepoConfig(\n",
    "            project=\"kubeflow-user\",\n",
    "            registry=registry_config,\n",
    "            provider=\"local\",\n",
    "            online_store=online_store_config\n",
    "        )\n",
    "        \n",
    "        self.fs = FeatureStore(config=repo_config, repo_path=None)\n",
    "\n",
    "    def preprocess(self, inputs: Dict):\n",
    "        enriched_data = self.fs.get_online_features(\n",
    "            entity_rows=[{\"driver_id\": driver_id} for driver_id in inputs[\"instances\"]],\n",
    "            features=[\n",
    "                \"daily_driver_stats_fv:comp_rate\",\n",
    "                \"daily_driver_stats_fv:acc_rate\",\n",
    "                \"daily_driver_stats_fv:trips\",\n",
    "                \"daily_driver_stats_fv:profit\",\n",
    "            ],\n",
    "        )\n",
    "        return {'instances': pd.DataFrame.from_dict(enriched_data.to_dict())}\n",
    "\n",
    "    def postprocess(self, inputs: Dict):\n",
    "        pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(ASSETS_PATH + \"transformer.py\", \"w\") as f:\n",
    "    f.write(TRANSFORMER_CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlmd = mlmdutils.get_mlmd_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer_artifact = artifacts.Transformer(\n",
    "    name=\"FeastTransformer\",\n",
    "    transformer_dir=ASSETS_PATH,\n",
    "    module_name=\"transformer\",\n",
    "    class_name=\"Transformer\",\n",
    "    is_stateful=True\n",
    ").submit_artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlmd.link_artifact_as_output(transformer_artifact.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Submit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlmd = mlmdutils.get_mlmd_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "signature = Signature(\n",
    "    input_size=[1] + [x.shape[1]],\n",
    "    output_size=[1] + [y.shape[1]],\n",
    "    input_dtype=x.dtypes,\n",
    "    output_dtype=y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_artifact = artifacts.SklearnModel(\n",
    "    model=model,\n",
    "    description=\"A driver ranking Linear Regression model\",\n",
    "    version=\"1.0.0\",\n",
    "    author=\"Kale\",\n",
    "    signature=signature,\n",
    "    tags={\"app\": \"feast-guide\"}).submit_artifact()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlmd.link_artifact_as_output(model_artifact.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "deploy_config": {},
   "docker_image": "gcr.io/arrikto-playground/jupyter-kale-py38@sha256:efdda3447fb76828634eb850be4df326f04e4545277bee41d67592342defaab8",
   "experiment": {
    "id": "new",
    "name": "model-workflow"
   },
   "experiment_name": "model-workflow",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "model-workflow-new",
   "snapshot_volumes": true,
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "feast-dev-workspace-5j8vz",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6eae61762843014baa3dac35aefd3cc07bf970b962c11c6cecd04b77dd2283a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
