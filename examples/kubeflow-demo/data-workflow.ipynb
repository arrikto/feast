{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Register Features Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from feast import Entity, FeatureStore, FeatureView, Field\n",
    "from feast.infra.offline_stores.contrib.postgres_offline_store.postgres_source import (\n",
    "    PostgreSQLSource,\n",
    ")\n",
    "from feast.infra.offline_stores.contrib.postgres_offline_store.postgres import PostgreSQLOfflineStoreConfig\n",
    "from feast.infra.online_stores.redis import RedisOnlineStoreConfig\n",
    "from feast.repo_config import RepoConfig, RegistryConfig\n",
    "from feast.types import Float32, Int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "functions"
    ]
   },
   "outputs": [],
   "source": [
    "def get_sqlalchemy_engine(config):\n",
    "    url = f\"postgresql+psycopg2://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "    print(\"Connecting to\", config[\"db_schema\"], \"schema using:\", url)\n",
    "    return sqlalchemy.create_engine(url, client_encoding='utf8', connect_args={'options': '-c search_path={}'.format(config[\"db_schema\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_config = {\n",
    "        \"user\": \"postgres\",\n",
    "        \"password\": \"postgres\",\n",
    "        \"host\": \"postgresql-offline-store.default.svc.cluster.local\",\n",
    "        \"port\": 5432,\n",
    "        \"database\": \"postgres\",\n",
    "        \"db_schema\": \"public\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Collection & Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For the purpose of this guide we will create dummy raw data that simulate the collection of data.\n",
    "\n",
    "In general, there are systems that are responsible for collecting raw data and storing them in a database or a data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:collect_data"
    ]
   },
   "outputs": [],
   "source": [
    "def create_trip_records_df(drivers, customers, start_date, end_date, order_count) -> pd.DataFrame:\n",
    "    \"\"\"    \n",
    "    accepted: Boolean flag indicating whether the trip order was accepted\n",
    "    completed: Boolean flag indicating whether the trip was completed\n",
    "    cost: cost of the trip (0.0 if not completed)\n",
    "    \n",
    "    Example df generated by this function:\n",
    "    |   order_id |   driver_id |   customer_id |   accepted |   completed |     cost | event_timestamp           |\n",
    "    |------------+-------------+---------------+------------+-------------+----------+---------------------------|\n",
    "    |        100 |        1005 |          5092 |          1 |           1 |  5.69582 | 2022-06-01 09:00:00+00:00 |\n",
    "    |        101 |        1011 |          5017 |          1 |           1 |  4.23811 | 2022-06-01 11:09:36+00:00 |\n",
    "    |        102 |        1010 |          5095 |          1 |           1 |  3.35814 | 2022-06-01 13:19:12+00:00 |\n",
    "    |        103 |        1005 |          5063 |          1 |           1 |  1.14626 | 2022-06-01 15:28:48+00:00 |\n",
    "    |        ... |        .... |          .... |        ... |         ... |      ... |                           |\n",
    "    |        150 |        1018 |          5005 |          1 |           1 |  7.19867 | 2022-06-01 19:48:00+00:00 |\n",
    "\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    df[\"order_id\"] = [order_id for order_id in range(100, 100 + order_count)]\n",
    "    df[\"driver_id\"] = np.random.choice(drivers, order_count)\n",
    "    df[\"customer_id\"] = np.random.choice(customers, order_count)\n",
    "    \n",
    "    df[\"accepted\"] = np.random.choice([0,1], size=order_count, p=[0.2, 0.8]).astype(np.int32)\n",
    "    df[\"completed\"] = np.random.choice([0,1], size=order_count, p=[0.1, 0.9]).astype(np.int32)\n",
    "    df[\"cost\"] = np.random.random(size=order_count).astype(np.float32) * 10\n",
    "    \n",
    "    df[\"event_timestamp\"] = [\n",
    "        pd.Timestamp(dt, unit=\"ms\", tz=\"UTC\").round(\"ms\")\n",
    "        for dt in pd.date_range(\n",
    "            start=start_date, end=end_date, periods=order_count+1, inclusive=\"left\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    df.sort_values(\n",
    "        by=[\n",
    "            \"event_timestamp\",\n",
    "            \"order_id\",\n",
    "            \"driver_id\",\n",
    "            \"customer_id\",\n",
    "        ],\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    for idx in df.index:\n",
    "        if df.loc[idx, \"accepted\"]== False:\n",
    "            df.loc[idx, \"completed\"] = 0\n",
    "            df.loc[idx, \"cost\"] = 0.0\n",
    "        if df.loc[idx, \"completed\"]== False:\n",
    "            df.loc[idx, \"cost\"] = 0.0\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drivers=list(range(1001, 1021))\n",
    "customers=list(range(5001, 5101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_date = datetime.utcnow().replace(microsecond=0, second=0, minute=0)\n",
    "start_date = end_date - timedelta(days=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records_df = create_trip_records_df(drivers, customers, start_date, end_date, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "con = get_sqlalchemy_engine(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records_df.to_sql(\n",
    "        name=\"trip_records\",\n",
    "        con=con,\n",
    "        schema=db_config[\"db_schema\"],\n",
    "        if_exists=\"replace\",\n",
    "        dtype={\n",
    "            \"order_id\": sqlalchemy.INT,\n",
    "            \"driver_id\": sqlalchemy.INT,\n",
    "            \"customer_id\": sqlalchemy.INT,\n",
    "            \"accepted\": sqlalchemy.BOOLEAN,\n",
    "            \"completed\": sqlalchemy.BOOLEAN,\n",
    "            \"cost\": sqlalchemy.FLOAT,\n",
    "            \"event_timestamp\": sqlalchemy.TIMESTAMP,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We fetch the collected data and start by getting some general information on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:explore_data",
     "prev:collect_data"
    ]
   },
   "outputs": [],
   "source": [
    "con = get_sqlalchemy_engine(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_records = pd.read_sql('trip_records', con, index_col=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[trip_records[\"cost\"] <= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We continue by inspecting the cost of the trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[trip_records[\"cost\"] > 0].describe(include=[\"float64\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(trip_records[trip_records[\"cost\"] > 0][\"cost\"], bins=100, linewidth=0.5, edgecolor=\"white\")\n",
    "\n",
    "ax.set(xlim=(0, 10), xticks=np.arange(1, 10),\n",
    "       ylim=(0, 20), yticks=np.linspace(0, 20, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "What is the average cost of a completed trip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[trip_records[\"completed\"] == True][\"cost\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "How many trip orders were not accepted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{trip_records[trip_records[\"accepted\"] == False].shape[0]}/1000 were not accepted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "How many trips were not completed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'{trip_records[(trip_records[\"accepted\"] == True) & (trip_records[\"completed\"] == False)].shape[0]}/{trip_records[trip_records[\"accepted\"] == True].shape[0]} were not completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we explore connections between drivers and trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[trip_records[\"accepted\"] == False][[\"driver_id\", \"accepted\"]].groupby([\"driver_id\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We see that some drivers reject trip orders more often than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[trip_records[\"completed\"] == True][[\"driver_id\", \"cost\"]].groupby([\"driver_id\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We also see that some drivers make more money compared to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before continuing we drop useless columns and keep the ones that we are interested in (driver_id, accepted, completed, cost, event_timestamp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records = trip_records.drop(labels=['order_id', 'customer_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In general, before creating a new feature we need to perform some kind of validation.\n",
    "\n",
    "We will perform some basic validation, since in this guide we are the ones creating the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We start by checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:validate_data",
     "prev:explore_data"
    ]
   },
   "outputs": [],
   "source": [
    "trip_records.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Then we check:\n",
    "- if rejected or uncompleted trips have non zero cost.\n",
    "- if a rejected trip order was completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "invalid_indexes = []\n",
    "\n",
    "for idx, row in trip_records.iterrows():\n",
    "    if row[\"accepted\"] == False and row[\"cost\"] != 0:\n",
    "        invalid_indexes.append(idx)\n",
    "    elif row[\"completed\"] == False and row[\"cost\"] != 0:\n",
    "        invalid_indexes.append(idx)\n",
    "    elif row[\"accepted\"] == False and row[\"completed\"] == True:\n",
    "        invalid_indexes.append(idx)\n",
    "    else:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records.drop(index=invalid_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We saw that there is a relation between drivers and trips.\n",
    "\n",
    "Drivers that accept more trips tend to earn more money.\n",
    "\n",
    "Thus, we will create the following features that we think will be useful for an ml model:\n",
    "- daily acceptance rate = accepted trip orders / total trip orders (per day)\n",
    "- daily completion rate = completed trips / accepted trip orders (per day)\n",
    "- daily trips = count of completed trips in a day\n",
    "- daily profit = sum of completed trips in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:build_features",
     "prev:validate_data"
    ]
   },
   "outputs": [],
   "source": [
    "daily_driver_stats = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will start by converting timestamp to dates (no hours, minutes, seconds, etc.) and dropping useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trip_records[\"event_timestamp\"] = trip_records[\"event_timestamp\"].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We continue by computing the daily trips and profit for each driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_stats = trip_records[trip_records[\"completed\"] == True][[\"driver_id\", \"event_timestamp\", \"completed\", \"cost\"]].groupby(by=[\"driver_id\", \"event_timestamp\"], as_index=False).agg({\"cost\" : \"sum\", \"completed\" : \"count\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_stats = daily_stats.rename(columns={\"completed\" : \"completed_trip_orders\", \"cost\" : \"profit\"})\n",
    "daily_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now, let's compute the daily total and accepted trip orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accepted_daily_stats = trip_records[trip_records[\"accepted\"] == True][[\"driver_id\", \"event_timestamp\", \"accepted\"]].groupby(by=[\"driver_id\", \"event_timestamp\"], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accepted_daily_stats = accepted_daily_stats.rename(columns={\"accepted\" : \"accepted_trip_orders\"})\n",
    "accepted_daily_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_daily_stats = trip_records[[\"driver_id\", \"event_timestamp\", \"accepted\"]].groupby(by=[\"driver_id\", \"event_timestamp\"], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_daily_stats = total_daily_stats.rename(columns={\"accepted\" : \"total_trip_orders\"})\n",
    "total_daily_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we will join the features into one dataframe and compute the acceptance and completion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats = total_daily_stats.join(accepted_daily_stats.set_index([\"driver_id\", \"event_timestamp\"]), how=\"outer\", on=[\"driver_id\", \"event_timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After the outer join there are rows where we have trip orders, but the driver accepted none of them (NaN)\n",
    "# Thus, we convert Nan to 0\n",
    "daily_driver_stats[\"accepted_trip_orders\"] = daily_driver_stats[\"accepted_trip_orders\"].fillna(0)\n",
    "daily_driver_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats = daily_driver_stats.join(daily_stats.set_index([\"driver_id\", \"event_timestamp\"]), how=\"outer\", on=[\"driver_id\", \"event_timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After the outer join there are rows where we have trip orders, but the driver completed none of them (NaN) and the profit is NaN as well\n",
    "# Thus, we convert Nan to 0 in both cases\n",
    "daily_driver_stats[\"completed_trip_orders\"] = daily_driver_stats[\"completed_trip_orders\"].fillna(0)\n",
    "daily_driver_stats[\"profit\"] = daily_driver_stats[\"profit\"].fillna(0)\n",
    "daily_driver_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats[\"acc_rate\"] = daily_driver_stats.apply(lambda x: x[\"accepted_trip_orders\"] / x[\"total_trip_orders\"], axis=1)\n",
    "daily_driver_stats[\"comp_rate\"] = daily_driver_stats.apply(lambda x: x[\"completed_trip_orders\"] / x[\"accepted_trip_orders\"] if x[\"accepted_trip_orders\"] != 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats = daily_driver_stats.drop(labels=[\"total_trip_orders\", \"accepted_trip_orders\"], axis=1)\n",
    "daily_driver_stats = daily_driver_stats.rename(columns={\"completed_trip_orders\" : \"trips\"})\n",
    "daily_driver_stats.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "It's now time to store the new features in the database or data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = get_sqlalchemy_engine(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats.to_sql(\n",
    "        name=\"daily_driver_stats\",\n",
    "        con=con,\n",
    "        schema=db_config[\"db_schema\"],\n",
    "        if_exists=\"replace\",\n",
    "        dtype={\n",
    "            \"driver_id\": sqlalchemy.INT,\n",
    "            \"event_timestamp\": sqlalchemy.TIMESTAMP,\n",
    "            \"profit\": sqlalchemy.FLOAT,\n",
    "            \"acc_rate\": sqlalchemy.FLOAT,\n",
    "            \"comp_rate\": sqlalchemy.FLOAT,  \n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Register Feature Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this last step of the process we create the required Feast definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:register_features",
     "prev:build_features"
    ]
   },
   "outputs": [],
   "source": [
    "offline_store_config = PostgreSQLOfflineStoreConfig(\n",
    "    host=\"postgresql-offline-store.default.svc.cluster.local\",\n",
    "    database=\"postgres\",\n",
    "    db_schema=\"public\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "online_store_config = RedisOnlineStoreConfig(\n",
    "    connection_string=\"redis-online-store.default.svc.cluster.local:6379,username=default,password=redis,db=0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "registry_config = RegistryConfig(\n",
    "    registry_store_type=\"KubeflowRegistryStore\",\n",
    "    path=\"\",\n",
    "    project=\"kubeflow-user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "repo_config = RepoConfig(\n",
    "    project=\"kubeflow-user\",\n",
    "    registry=registry_config,\n",
    "    provider=\"local\",\n",
    "    offline_store=offline_store_config,\n",
    "    online_store=online_store_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = FeatureStore(config=repo_config, repo_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We create a data source definition that contains information on where the data lives, the name of the SQL table, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "daily_driver_stats_source = PostgreSQLSource(\n",
    "    name=\"daily_driver_stats_source\",\n",
    "    query=\"SELECT * FROM daily_driver_stats\",\n",
    "    timestamp_field=\"event_timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We define an entity that keeps information about its type, the join key , etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = Entity(\n",
    "    name=\"driver\",\n",
    "    value_type=Int64,\n",
    "    description=\"\",\n",
    "    join_keys=[\"driver_id\"],\n",
    "    tags={},\n",
    "    owner=\"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We create a feature view definition that contains the features we created previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver_daily_stats_fv = FeatureView(\n",
    "    name=\"daily_driver_stats_fv\",\n",
    "    entities=[\"driver\"],\n",
    "    description=\"\",\n",
    "    tags={},\n",
    "    owner=\"user\",\n",
    "    ttl=timedelta(days=7),\n",
    "    source=daily_driver_stats_source,\n",
    "    online=True,\n",
    "    schema=[\n",
    "        Field(name=\"acc_rate\", dtype=Float32, tags={}),\n",
    "        Field(name=\"comp_rate\", dtype=Float32, tags={}),\n",
    "        Field(name=\"profit\", dtype=Float32, tags={}),\n",
    "        Field(name=\"trips\", dtype=Int64, tags={})\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "By running the appply method, we push the definitions to the registry and update the infrastructure (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs.apply([daily_driver_stats_source, driver, driver_daily_stats_fv])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('env')",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "deploy_config": {},
   "docker_image": "gcr.io/arrikto/jupyter-kale-py38@sha256:08ec067e1910993d1c4dc8fe100613ffd2e8f482698a1ebc0504cd07459686da",
   "experiment": {
    "id": "new",
    "name": "data-workflow"
   },
   "experiment_name": "data-workflow",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "data-workflow",
   "snapshot_volumes": true,
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "feast-dev-workspace-mfczb",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6eae61762843014baa3dac35aefd3cc07bf970b962c11c6cecd04b77dd2283a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
